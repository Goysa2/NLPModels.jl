<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="no-js ie6"><![endif]-->
<!--[if IE 7 ]><html class="no-js ie7"><![endif]-->
<!--[if IE 8 ]><html class="no-js ie8"><![endif]-->
<!--[if IE 9 ]><html class="no-js ie9"><![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    
      
        <title>API - NLPModels.jl</title>
      
      
      
      
        <meta name="author" content="JuliaSmoothOptimizers">
      
    
    <meta property="og:url" content="None">
    <meta property="og:title" content="NLPModels.jl">
    <meta property="og:image" content="None/../">
    <meta name="apple-mobile-web-app-title" content="NLPModels.jl">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
    
    <link rel="shortcut icon" type="image/x-icon" href="../assets/images/favicon-e565ddfa3b.ico">
    <link rel="icon" type="image/x-icon" href="../assets/images/favicon-e565ddfa3b.ico">
    <style>
      @font-face {
      	font-family: 'Icon';
      	src: url('../assets/fonts/icon.eot?52m981');
      	src: url('../assets/fonts/icon.eot?#iefix52m981')
               format('embedded-opentype'),
      		   url('../assets/fonts/icon.woff?52m981')
               format('woff'),
      		   url('../assets/fonts/icon.ttf?52m981')
               format('truetype'),
      		   url('../assets/fonts/icon.svg?52m981#icon')
               format('svg');
      	font-weight: normal;
      	font-style: normal;
      }
    </style>
    <link rel="stylesheet" href="../assets/stylesheets/application-a422ff04cc.css">
    
      <link rel="stylesheet" href="../assets/stylesheets/palettes-05ab2406df.css">
    
    
      
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,700|Ubuntu+Mono">
      <style>
        body, input {
          font-family: 'Ubuntu', Helvetica, Arial, sans-serif;
        }
        pre, code {
          font-family: 'Ubuntu Mono', 'Courier New', 'Courier', monospace;
        }
      </style>
    
    
      <link rel="stylesheet" href="../assets/Documenter.css">
    
      <link rel="stylesheet" href="../assets/style.css">
    
    <script src="../assets/javascripts/modernizr-4ab42b99fd.js"></script>
    
  </head>
  
  
  
  <body class="palette-primary-deep-orange palette-accent-indigo">
    
      
      
    
    <div class="backdrop">
      <div class="backdrop-paper"></div>
    </div>
    <input class="toggle" type="checkbox" id="toggle-drawer">
    <input class="toggle" type="checkbox" id="toggle-search">
    <label class="toggle-button overlay" for="toggle-drawer"></label>
    <header class="header">
      <nav aria-label="Header">
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>
    <div class="stretch">
      <div class="title">
        
          <span class="path">
            
          </span>
        
        API
      </div>
    </div>
    
    
      
      <div class="button button-github" role="button" aria-label="GitHub">
        <a href="https://github.com/JuliaSmoothOptimizers" title="@JuliaSmoothOptimizers on GitHub" target="_blank" class="toggle-button icon icon-github"></a>
      </div>
    
    <div class="button button-search" role="button" aria-label="Search">
      <label class="toggle-button icon icon-search" title="Search" for="toggle-search"></label>
    </div>
  </div>
  <div class="bar search">
    <div class="button button-close" role="button" aria-label="Close">
      <label class="toggle-button icon icon-back" for="toggle-search"></label>
    </div>
    <div class="stretch">
      <div class="field">
        <input class="query" type="text" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck>
      </div>
    </div>
    <div class="button button-reset" role="button" aria-label="Search">
      <button class="toggle-button icon icon-close" id="reset-search"></button>
    </div>
  </div>
</nav>
    </header>
    <main class="main">
      
      <div class="drawer">
        <nav aria-label="Navigation">
  
  <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl" class="project">
    <div class="banner">
      
      <div class="name">
        <strong>
          NLPModels.jl
          <span class="version">
            
          </span>
        </strong>
        
          <br>
          JuliaSmoothOptimizers/NLPModels.jl
        
      </div>
    </div>
  </a>
  <div class="scrollable">
    <div class="wrapper">
      
        <ul class="repo">
          <li class="repo-download">
            
            <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/archive/master.zip" target="_blank" title="Download" data-action="download">
              <i class="icon icon-download"></i> Download
            </a>
          </li>
          <li class="repo-stars">
            <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/stargazers" target="_blank" title="Stargazers" data-action="star">
              <i class="icon icon-star"></i> Stars
              <span class="count">&ndash;</span>
            </a>
          </li>
        </ul>
        <hr>
      
      <div class="toc">
        <ul>
          
            
  <li>
    <a class="" title="Home" href="..">
      Home
    </a>
    
  </li>

          
            
  <li>
    <a class="" title="Models" href="../models/">
      Models
    </a>
    
  </li>

          
            
  <li>
    <a class="" title="Tutorial" href="../tutorial/">
      Tutorial
    </a>
    
  </li>

          
            
  <li>
    <a class="current" title="API" href="./">
      API
    </a>
    
      
        
      
      
        <ul>
          
            <li class="anchor">
              <a title="Reference guide" href="#reference-guide">
                Reference guide
              </a>
            </li>
          
            <li class="anchor">
              <a title="AbstractNLPModel functions" href="#abstractnlpmodel-functions">
                AbstractNLPModel functions
              </a>
            </li>
          
            <li class="anchor">
              <a title="Derivative check" href="#derivative-check">
                Derivative check
              </a>
            </li>
          
        </ul>
      
    
  </li>

          
            
  <li>
    <a class="" title="Remissive Index" href="../remissive-index/">
      Remissive Index
    </a>
    
  </li>

          
        </ul>
        
          <hr>
          <span class="section">The author</span>
          <ul>
            
            
              
              <li>
                <a href="https://github.com/JuliaSmoothOptimizers" target="_blank" title="@JuliaSmoothOptimizers on GitHub">
                  @JuliaSmoothOptimizers on GitHub
                </a>
              </li>
            
          </ul>
        
      </div>
    </div>
  </div>
</nav>
      </div>
      <article class="article">
        <div class="wrapper">
          
          <p><a id='API-1'></a></p>
<h1 id="api">API</h1>
<p>As stated in the <a href="../home">home</a> page, we consider the nonlinear optimization problem in the following format: <script type="math/tex; mode=display">\begin{align*} \min \quad & f(x) \\
& c_L \leq c(x) \leq c_U \\
& \ell \leq x \leq u. \end{align*}</script> To develop an optimization algorithm, we are usually worried not only with $f(x)$ and $c(x)$, but also with their derivatives. Namely,</p>
<ul>
<li>$\nabla f(x)$, the gradient of $f$ at the point $x$;</li>
<li>$\nabla^2 f(x)$, the Hessian of $f$ at the point $x$;</li>
<li>$J(x) = \nabla c(x)$, the Jacobian of $c$ at the point $x$;</li>
<li>$\nabla^2 f(x) + \sum_{i=1}^m \lambda_i \nabla^2 c_i(x)$,   the Hessian of the Lagrangian function at the point $(x,\lambda)$.</li>
</ul>
<p>There are many ways to access some of these values, so here is a little reference guide.</p>
<p><a id='Reference-guide-1'></a></p>
<h2 id="reference-guide">Reference guide</h2>
<p>The following naming should be easy enough to follow. If not, click on the link and go to the description.</p>
<ul>
<li><code>!</code> means inplace;</li>
<li><code>_coord</code> means coordinate format;</li>
<li><code>prod</code> means matrix-vector product;</li>
<li><code>_op</code> means operator (as in <a href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl">LinearOperators.jl</a>).</li>
</ul>
<p>Feel free to open an issue to suggest other methods that should apply to all NLPModels instances.</p>
<table>
<thead>
<tr>
<th align="right">Function</th>
<th align="right">NLPModels function</th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">$f(x)$</td>
<td align="right"><a href="../api/#NLPModels.obj">obj</a></td>
</tr>
<tr>
<td align="right">$\nabla f(x)$</td>
<td align="right"><a href="../api/#NLPModels.grad">grad</a>, <a href="../api/#NLPModels.grad!">grad!</a></td>
</tr>
<tr>
<td align="right">$\nabla^2 f(x)$</td>
<td align="right"><a href="../api/#NLPModels.hess">hess</a>, <a href="../api/#NLPModels.hess_op">hess_op</a>, <a href="../api/#NLPModels.hess_coord">hess_coord</a>, <a href="../api/#NLPModels.hprod">hprod</a>, <a href="../api/#NLPModels.hprod!">hprod!</a></td>
</tr>
<tr>
<td align="right">$c(x)$</td>
<td align="right"><a href="../api/#NLPModels.cons">cons</a>, <a href="../api/#NLPModels.cons!">cons!</a></td>
</tr>
<tr>
<td align="right">$J(x)$</td>
<td align="right"><a href="../api/#NLPModels.jac">jac</a>, <a href="../api/#NLPModels.jac_coord">jac_coord</a>, <a href="../api/#NLPModels.jprod">jprod</a>, <a href="../api/#NLPModels.jprod!">jprod!</a>, <a href="../api/#NLPModels.jtprod">jtprod</a>, <a href="../api/#NLPModels.jtprod!">jtprod!</a></td>
</tr>
<tr>
<td align="right">$\nabla^2 L(x,y)$</td>
<td align="right"><a href="../api/#NLPModels.hess">hess</a>, <a href="../api/#NLPModels.hess_op">hess_op</a>, <a href="../api/#NLPModels.hess_coord">hess_coord</a>, <a href="../api/#NLPModels.hprod">hprod</a>, <a href="../api/#NLPModels.hprod!">hprod!</a></td>
</tr>
</tbody>
</table>
<p><a id='AbstractNLPModel-functions-1'></a></p>
<h2 id="abstractnlpmodel-functions">AbstractNLPModel functions</h2>
<p><a id='NLPModels.obj' href='#NLPModels.obj'>#</a>
<strong><code>NLPModels.obj</code></strong> &mdash; <em>Function</em>.</p>
<p><code>obj(nlp, x)</code></p>
<p>Evaluate $f(x)$, the objective function of <code>nlp</code> at <code>x</code>.</p>
<p><a id='NLPModels.grad' href='#NLPModels.grad'>#</a>
<strong><code>NLPModels.grad</code></strong> &mdash; <em>Function</em>.</p>
<p><code>grad(nlp, x)</code></p>
<p>Evaluate $\nabla f(x)$, the gradient of the objective function at <code>x</code>.</p>
<p><a id='NLPModels.grad!' href='#NLPModels.grad!'>#</a>
<strong><code>NLPModels.grad!</code></strong> &mdash; <em>Function</em>.</p>
<p><code>grad!(nlp, x, g)</code></p>
<p>Evaluate $\nabla f(x)$, the gradient of the objective function at <code>x</code> in place.</p>
<p><a id='NLPModels.cons' href='#NLPModels.cons'>#</a>
<strong><code>NLPModels.cons</code></strong> &mdash; <em>Function</em>.</p>
<p><code>cons(nlp, x)</code></p>
<p>Evaluate $c(x)$, the constraints at <code>x</code>.</p>
<p><a id='NLPModels.cons!' href='#NLPModels.cons!'>#</a>
<strong><code>NLPModels.cons!</code></strong> &mdash; <em>Function</em>.</p>
<p><code>cons!(nlp, x, c)</code></p>
<p>Evaluate $c(x)$, the constraints at <code>x</code> in place.</p>
<p><a id='NLPModels.jac_coord' href='#NLPModels.jac_coord'>#</a>
<strong><code>NLPModels.jac_coord</code></strong> &mdash; <em>Function</em>.</p>
<p><code>(rows,cols,vals) = jac_coord(nlp, x)</code></p>
<p>Evaluate $\nabla c(x)$, the constraint's Jacobian at <code>x</code> in sparse coordinate format.</p>
<p><a id='NLPModels.jac' href='#NLPModels.jac'>#</a>
<strong><code>NLPModels.jac</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Jx = jac(nlp, x)</code></p>
<p>Evaluate $\nabla c(x)$, the constraint's Jacobian at <code>x</code> as a sparse matrix.</p>
<p><a id='NLPModels.jprod' href='#NLPModels.jprod'>#</a>
<strong><code>NLPModels.jprod</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Jv = jprod(nlp, x, v)</code></p>
<p>Evaluate $\nabla c(x)v$, the Jacobian-vector product at <code>x</code>.</p>
<p><a id='NLPModels.jprod!' href='#NLPModels.jprod!'>#</a>
<strong><code>NLPModels.jprod!</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Jv = jprod!(nlp, x, v, Jv)</code></p>
<p>Evaluate $\nabla c(x)v$, the Jacobian-vector product at <code>x</code> in place.</p>
<p><a id='NLPModels.jtprod' href='#NLPModels.jtprod'>#</a>
<strong><code>NLPModels.jtprod</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Jtv = jtprod(nlp, x, v, Jtv)</code></p>
<p>Evaluate $\nabla c(x)^Tv$, the transposed-Jacobian-vector product at <code>x</code>.</p>
<p><a id='NLPModels.jtprod!' href='#NLPModels.jtprod!'>#</a>
<strong><code>NLPModels.jtprod!</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Jtv = jtprod!(nlp, x, v, Jtv)</code></p>
<p>Evaluate $\nabla c(x)^Tv$, the transposed-Jacobian-vector product at <code>x</code> in place.</p>
<p><a id='NLPModels.hess_coord' href='#NLPModels.hess_coord'>#</a>
<strong><code>NLPModels.hess_coord</code></strong> &mdash; <em>Function</em>.</p>
<p><code>(rows,cols,vals) = hess_coord(nlp, x; obj_weight=1.0, y=zeros)</code></p>
<p>Evaluate the Lagrangian Hessian at <code>(x,y)</code> in sparse coordinate format, with objective function scaled by <code>obj_weight</code>, i.e.,</p>
<p>
<script type="math/tex; mode=display"> \nabla^2L(x,y) = \sigma * \nabla^2 f(x) + \sum_{i=1}^m y_i\nabla^2 c_i(x), </script>
</p>
<p>with σ = obj_weight. Only the lower triangle is returned.</p>
<p><a id='NLPModels.hess' href='#NLPModels.hess'>#</a>
<strong><code>NLPModels.hess</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Hx = hess(nlp, x; obj_weight=1.0, y=zeros)</code></p>
<p>Evaluate the Lagrangian Hessian at <code>(x,y)</code> as a sparse matrix, with objective function scaled by <code>obj_weight</code>, i.e.,</p>
<p>
<script type="math/tex; mode=display"> \nabla^2L(x,y) = \sigma * \nabla^2 f(x) + \sum_{i=1}^m y_i\nabla^2 c_i(x), </script>
</p>
<p>with σ = obj_weight. Only the lower triangle is returned.</p>
<p><a id='NLPModels.hess_op' href='#NLPModels.hess_op'>#</a>
<strong><code>NLPModels.hess_op</code></strong> &mdash; <em>Function</em>.</p>
<p><code>H = hess_op(nlp, x; obj_weight=1.0, y=zeros)</code></p>
<p>Return the Lagrangian Hessian at <code>(x,y)</code> with objective function scaled by <code>obj_weight</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>H * v</code>. The linear operator H represents</p>
<p>
<script type="math/tex; mode=display"> \nabla^2L(x,y) = \sigma * \nabla^2 f(x) + \sum_{i=1}^m y_i\nabla^2 c_i(x), </script>
</p>
<p>with σ = obj_weight.</p>
<p><a id='NLPModels.hprod' href='#NLPModels.hprod'>#</a>
<strong><code>NLPModels.hprod</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Hv = hprod(nlp, x, v; obj_weight=1.0, y=zeros)</code></p>
<p>Evaluate the product of the Lagrangian Hessian at <code>(x,y)</code> with the vector <code>v</code>, with objective function scaled by <code>obj_weight</code>, i.e.,</p>
<p>
<script type="math/tex; mode=display"> \nabla^2L(x,y) = \sigma * \nabla^2 f(x) + \sum_{i=1}^m y_i\nabla^2 c_i(x), </script>
</p>
<p>with σ = obj_weight.</p>
<p><a id='NLPModels.hprod!' href='#NLPModels.hprod!'>#</a>
<strong><code>NLPModels.hprod!</code></strong> &mdash; <em>Function</em>.</p>
<p><code>Hv = hprod!(nlp, x, v, Hv; obj_weight=1.0, y=zeros)</code></p>
<p>Evaluate the product of the Lagrangian Hessian at <code>(x,y)</code> with the vector <code>v</code> in place, with objective function scaled by <code>obj_weight</code>, i.e.,</p>
<p>
<script type="math/tex; mode=display"> \nabla^2L(x,y) = \sigma * \nabla^2 f(x) + \sum_{i=1}^m y_i\nabla^2 c_i(x), </script>
</p>
<p>with σ = obj_weight.</p>
<p><a id='NLPModels.NLPtoMPB' href='#NLPModels.NLPtoMPB'>#</a>
<strong><code>NLPModels.NLPtoMPB</code></strong> &mdash; <em>Function</em>.</p>
<div class="code"><pre><span></span>mp = NLPtoMPB(nlp, solver)
</pre></div>


<p>Return a <code>MathProgBase</code> model corresponding to an <code>AbstractNLPModel</code>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>nlp::AbstractNLPModel</code></li>
<li><code>solver::AbstractMathProgSolver</code> a solver instance, e.g., <code>IpoptSolver()</code></li>
</ul>
<p>Currently, all models are treated as nonlinear models.</p>
<p><strong>Return values</strong></p>
<p>The function returns a <code>MathProgBase</code> model <code>mpbmodel</code> such that it should be possible to call</p>
<div class="code"><pre><span></span>MathProgBase.optimize!(mpbmodel)
</pre></div>


<p><a id='LinearOperators.reset!' href='#LinearOperators.reset!'>#</a>
<strong><code>LinearOperators.reset!</code></strong> &mdash; <em>Function</em>.</p>
<p><code>reset!(counters)</code></p>
<p>Reset evaluation counters</p>
<p>`reset!(nlp)</p>
<p>Reset evaluation count in <code>nlp</code></p>
<p><a id='Derivative-check-1'></a></p>
<h2 id="derivative-check">Derivative check</h2>
<p><a id='NLPModels.gradient_check' href='#NLPModels.gradient_check'>#</a>
<strong><code>NLPModels.gradient_check</code></strong> &mdash; <em>Function</em>.</p>
<p>Check the first derivatives of the objective at <code>x</code> against centered finite differences.</p>
<p>This function returns a dictionary indexed by components of the gradient for which the relative error exceeds <code>rtol</code>.</p>
<p><a id='NLPModels.jacobian_check' href='#NLPModels.jacobian_check'>#</a>
<strong><code>NLPModels.jacobian_check</code></strong> &mdash; <em>Function</em>.</p>
<p>Check the first derivatives of the constraints at <code>x</code> against centered finite differences.</p>
<p>This function returns a dictionary indexed by (j, i) tuples such that the relative error in the <code>i</code>-th partial derivative of the <code>j</code>-th constraint exceeds <code>rtol</code>.</p>
<p><a id='NLPModels.hessian_check' href='#NLPModels.hessian_check'>#</a>
<strong><code>NLPModels.hessian_check</code></strong> &mdash; <em>Function</em>.</p>
<p>Check the second derivatives of the objective and each constraints at <code>x</code> against centered finite differences. This check does not rely on exactness of the first derivatives, only on objective and constraint values.</p>
<p>The <code>sgn</code> arguments refers to the formulation of the Lagrangian in the problem. It should have a positive value if the Lagrangian is formulated as</p>
<div class="code"><pre><span></span>L(x,y) = f(x) + ∑ yⱼ cⱼ(x)
</pre></div>


<p>e.g., as in <code>JuMPNLPModel</code>s, and a negative value if the Lagrangian is formulated as</p>
<div class="code"><pre><span></span>L(x,y) = f(x) - ∑ yⱼ cⱼ(x)
</pre></div>


<p>e.g., as in <code>AmplModel</code>s. Only the sign of <code>sgn</code> is important.</p>
<p>This function returns a dictionary indexed by functions. The 0-th function is the objective while the k-th function (for k &gt; 0) is the k-th constraint. The values of the dictionary are dictionaries indexed by tuples (i, j) such that the relative error in the second derivative ∂²fₖ/∂xᵢ∂xⱼ exceeds <code>rtol</code>.</p>
<p><a id='NLPModels.hessian_check_from_grad' href='#NLPModels.hessian_check_from_grad'>#</a>
<strong><code>NLPModels.hessian_check_from_grad</code></strong> &mdash; <em>Function</em>.</p>
<p>Check the second derivatives of the objective and each constraints at <code>x</code> against centered finite differences. This check assumes exactness of the first derivatives.</p>
<p>The <code>sgn</code> arguments refers to the formulation of the Lagrangian in the problem. It should have a positive value if the Lagrangian is formulated as</p>
<div class="code"><pre><span></span>L(x,y) = f(x) + ∑ yⱼ cⱼ(x)
</pre></div>


<p>e.g., as in <code>JuMPNLPModel</code>s, and a negative value if the Lagrangian is formulated as</p>
<div class="code"><pre><span></span>L(x,y) = f(x) - ∑ yⱼ cⱼ(x)
</pre></div>


<p>e.g., as in <code>AmplModel</code>s. Only the sign of <code>sgn</code> is important.</p>
<p>This function returns a dictionary indexed by functions. The 0-th function is the objective while the k-th function (for k &gt; 0) is the k-th constraint. The values of the dictionary are dictionaries indexed by tuples (i, j) such that the relative error in the second derivative ∂²fₖ/∂xᵢ∂xⱼ exceeds <code>rtol</code>.</p>
          <aside class="copyright" role="note">
            
            Documentation built with
            <a href="http://www.mkdocs.org" target="_blank">MkDocs</a>
            using the
            <a href="http://squidfunk.github.io/mkdocs-material/" target="_blank">
              Material
            </a>
            theme.
          </aside>
          
            <footer class="footer">
              
  <nav class="pagination" aria-label="Footer">
    <div class="previous">
      
        <a href="../tutorial/" title="Tutorial">
          <span class="direction">
            Previous
          </span>
          <div class="page">
            <div class="button button-previous" role="button" aria-label="Previous">
              <i class="icon icon-back"></i>
            </div>
            <div class="stretch">
              <div class="title">
                Tutorial
              </div>
            </div>
          </div>
        </a>
      
    </div>
    <div class="next">
      
        <a href="../remissive-index/" title="Remissive Index">
          <span class="direction">
            Next
          </span>
          <div class="page">
            <div class="stretch">
              <div class="title">
                Remissive Index
              </div>
            </div>
            <div class="button button-next" role="button" aria-label="Next">
              <i class="icon icon-forward"></i>
            </div>
          </div>
        </a>
      
    </div>
  </nav>

            </footer>
          
        </div>
      </article>
      <div class="results" role="status" aria-live="polite">
        <div class="scrollable">
          <div class="wrapper">
            <div class="meta"></div>
            <div class="list"></div>
          </div>
        </div>
      </div>
    </main>
    <script>
      var base_url = '..';
      var repo_id  = 'JuliaSmoothOptimizers/NLPModels.jl';
    </script>
    <script src="../assets/javascripts/application-997097ee0c.js"></script>
    
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
    
      <script src="../assets/mathjaxhelper.js"></script>
    
    
  </body>
</html>